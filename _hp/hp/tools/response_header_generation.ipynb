{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9970141-e3b2-4078-8623-605c27dcdb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import httpx\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "from itertools import permutations, product, chain\n",
    "\n",
    "from hp.tools.models import Response, Session\n",
    "from hp.tools.crawler.utils import get_or_create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37007b0f-02da-4a16-b139-0b8cbb747a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_casing(input_string, seed=42):\n",
    "    \"\"\"Randomize the casing of a string (fixed with a seed).\"\"\"\n",
    "    random.seed(seed)\n",
    "    return ''.join(random.choice([c.upper(), c.lower()]) for c in input_string)\n",
    "\n",
    "def insert_char_middle(input_string, char):\n",
    "    \"\"\"Insert a char in the middle of a string.\"\"\"\n",
    "    middle_index = len(input_string) // 2\n",
    "    return input_string[:middle_index] + char + input_string[middle_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d1331e-92c3-4b77-a7cd-f71c49bb9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the mutations we apply on strings such as header names and header values\n",
    "# Some of them may have no effect and result in duplicates; however such duplicates are not saved in the db\n",
    "\n",
    "all_upper = lambda x: x.upper()\n",
    "all_lower = lambda x: x.lower()\n",
    "random_case = lambda x: randomize_casing(x)\n",
    "leadtrail_space = lambda x: \" \" + x + \" \"\n",
    "in_double_quotes = lambda x: '\"' + x + '\"'\n",
    "in_single_quotes = lambda x: \"'\" + x + \"'\"\n",
    "remove_whitespace = lambda x: x.replace(\" \", \"\")\n",
    "double_spaces = lambda x: x.replace(\" \", \"  \")\n",
    "space_to_tab = lambda x: x.replace(\" \", \"\\t\")\n",
    "\n",
    "lead_seqs = []\n",
    "trail_seqs = []\n",
    "middle_seqs = []\n",
    "\n",
    "# All all ASCII chars as leading, trailing, and middle char\n",
    "ascii_chars = [char for char in map(chr, range(128))]\n",
    "# Alternatively use less ones? All/Some control chars? + space, comma, ....\n",
    "# ascii_chars = [char for char in map(chr, range(32))] + [\" \", \",\", \";\", \":\"]\n",
    "for seq in ascii_chars:\n",
    "    lead_seqs.append(lambda x, s=seq: s + x)\n",
    "    trail_seqs.append(lambda x, s=seq: x + s)\n",
    "    middle_seqs.append(lambda x, s=seq: insert_char_middle(x, s))\n",
    "\n",
    "# Add other interesting leading, trailing, middle chars: Double space, non-breaking space, full-width comma\n",
    "# MAYBE: add more?\n",
    "other_chars = [\"  \", \"\\u00A0a\", \"\\uFF0C\"]\n",
    "for seq in other_chars:\n",
    "    lead_seqs.append(lambda x, s=seq: s + x)\n",
    "    trail_seqs.append(lambda x, s=seq: x + s)\n",
    "    middle_seqs.append(lambda x, s=seq: insert_char_middle(x, s))\n",
    "\n",
    "# Replace some chars with others\n",
    "chars_to_replace = [\";\", \",\", \":\", \"=\", \"'\", '\"', \"-\", \"_\"]\n",
    "# Replace each of the above with all of the below\n",
    "replace_chars = [\n",
    "    \"\", \" \", \";\", \",\", \":\", \"=\", \"-\", \"_\",\n",
    "    \"'\", '\"', \"`\", \"´\",\n",
    "    '\\u2018',  # Left Single Quotation Mark\n",
    "    '\\u2019',  # Right Single Quotation Mark\n",
    "    '\\u201A',  # Single Low-9 Quotation Mark\n",
    "    '\\u201B',  # Single High-Reversed-9 Quotation Mark\n",
    "    '\\u201C',  # Left Double Quotation Mark\n",
    "    '\\u201D',  # Right Double Quotation Mark\n",
    "    '\\u201E',  # Double Low-9 Quotation Mark\n",
    "    '\\u201F',  # Double High-Reversed-9 Quotation Mark\n",
    "]\n",
    "replace_funcs = []\n",
    "for char in chars_to_replace:\n",
    "    for rp in replace_chars:\n",
    "        if rp == char:\n",
    "            continue\n",
    "        replace_funcs.append(lambda x, c1=char, c2=rp: x.replace(c1, c2))\n",
    "\n",
    "\n",
    "\n",
    "general_mutations = [\n",
    "    all_upper,\n",
    "    all_lower,\n",
    "    random_case,\n",
    "    leadtrail_space,\n",
    "    in_double_quotes,\n",
    "    in_single_quotes,\n",
    "    remove_whitespace,\n",
    "    double_spaces,\n",
    "    space_to_tab,\n",
    "    *lead_seqs,\n",
    "    *trail_seqs,\n",
    "    *middle_seqs,\n",
    "    *replace_funcs,\n",
    "]\n",
    "\n",
    "basic_mutations = [\n",
    "    #all_upper,\n",
    "    all_lower,\n",
    "    random_case,\n",
    "    leadtrail_space,\n",
    "]\n",
    "\n",
    "\n",
    "def mutate_header_name(header_name):\n",
    "    header_names = set()\n",
    "    for mutation in general_mutations:\n",
    "        header_names.add(mutation(header_name))\n",
    "    return header_names\n",
    "\n",
    "def mutate_header_value(header_value, mutation_list=general_mutations):\n",
    "    header_values = set()\n",
    "    for mutation in mutation_list:\n",
    "        header_values.add(mutation(header_value))\n",
    "    return header_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1444a677-14a2-4216-9256-245ac122d886",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D E\"N\\'Y', \"oD EN'Y\", \"\\x07D EN'Y\", \"D EtN'Y\", \"\\x01D EN'Y\", \"}D EN'Y\", \"D E\\x16N'Y\", 'D EN-Y', \"%D EN'Y\", \"D E&N'Y\", \"rD EN'Y\", \"TD EN'Y\", \"D EN'YM\", \"D EMN'Y\", \"D EN'Y&\", \"D EN'Yc\", \"D EN'Y\\x00\", 'D EN\\'Y\"', \"D E\\x10N'Y\", \"D EN'YX\", \"qD EN'Y\", \"ED EN'Y\", \"D E\\x0eN'Y\", \"uD EN'Y\", \"_D EN'Y\", \"D EN'Y\\x10\", \"-D EN'Y\", \"D EN'Y\\x1a\", \"\\x05D EN'Y\", \"zD EN'Y\", \"[D EN'Y\", \"7D EN'Y\", \"/D EN'Y\", \"\\tD EN'Y\", \"'D EN'Y\", \"D EN'Yi\", \"D EN'YU\", \"D EIN'Y\", \"yD EN'Y\", \"D EN'Y2\", \"D EN'Y7\", \"D E6N'Y\", \"D EN'Y\\x0f\", \"D EBN'Y\", \"D EN'Y\\x1d\", \"~D EN'Y\", \"JD EN'Y\", \"\\x02D EN'Y\", \"D EN'Yp\", \"D EN'Y\\x1f\", \"D E.N'Y\", \"D EN'Y\\x05\", \"CD EN'Y\", \"D E\\x7fN'Y\", \"D E\\rN'Y\", \"D EEN'Y\", \"\\x12D EN'Y\", \"D E\\x1aN'Y\", \"D E4N'Y\", \"SD EN'Y\", 'D EN’Y', \"D E*N'Y\", \"D E\\x11N'Y\", \"D EN'Y\\x07\", \"D EN'Y\\x0c\", \"4D EN'Y\", 'D EN Y', \"HD EN'Y\", \"#D EN'Y\", \"D E\\x04N'Y\", \"D EN'Yr\", 'D EN‚Y', \"D EN'Y|\", \"D EvN'Y\", \"D EN'Y,\", \"\\x14D EN'Y\", \"D E\\x1cN'Y\", \"D EN'Y$\", \"D EN'Y>\", \"D EN'Y9\", 'D EN”Y', \"D EN'Y5\", \"D E@N'Y\", \"YD EN'Y\", \"D E\\x1bN'Y\", \"^D EN'Y\", \"D EN'Y\\x02\", \"MD EN'Y\", \"ND EN'Y\", \"\\x04D EN'Y\", \"OD EN'Y\", \"@D EN'Y\", \"DD EN'Y\", \"D EN'Y\\x03\", \"D EN'YP\", \"D E<N'Y\", \"D EdN'Y\", \"D E\\x03N'Y\", \"D E2N'Y\", \"D EN'YB\", \"|D EN'Y\", \"D EoN'Y\", \"D EN'Y/\", \"`D EN'Y\", \"\\x1cD EN'Y\", \"D EN'YV\", \"D E'N'Y\", \"D EN'Y\\xa0a\", \"\\x17D EN'Y\", \"D EbN'Y\", \"mD EN'Y\", \"D E\\x18N'Y\", \"WD EN'Y\", \"D EN'Y\\r\", \"D EN'Yh\", \"D EN'YZ\", \"\\x00D EN'Y\", \"D E\\x0fN'Y\", \"D E0N'Y\", '\"D EN\\'Y\"', \"D EN'YW\", \"1D EN'Y\", \">D EN'Y\", \"D EN'Y+\", \"D EN'Y\\x06\", \"D E?N'Y\", \"D EN'Y#\", 'D EN:Y', \"D EN'Y*\", \"D E-N'Y\", \"D EN'Y_\", \"D EN'Y}\", \"lD EN'Y\", \"D EN'Y\\x01\", \"\\x13D EN'Y\", \"{D EN'Y\", 'D EN`Y', \"D ELN'Y\", \"D EN'Y4\", \"D EiN'Y\", \"vD EN'Y\", \",D EN'Y\", \"KD EN'Y\", \"&D EN'Y\", \"\\x18D EN'Y\", \"9D EN'Y\", 'D EN\"Y', \"D EDN'Y\", \"D EgN'Y\", \"D EN'Y=\", \"D EN'Y'\", \"D EN'Y`\", \"，D EN'Y\", \"D EN'Y\\x04\", \"D EeN'Y\", 'D EN_Y', \"8D EN'Y\", \":D EN'Y\", \"D EPN'Y\", \"D EN'Y6\", \"5D EN'Y\", \"\\xa0aD EN'Y\", \"D E\\x07N'Y\", \"D EN'Yt\", \"D EN'Yw\", \"D EWN'Y\", \"fD EN'Y\", \"D EhN'Y\", \"\\x0cD EN'Y\", \"D EON'Y\", \"D E\\x08N'Y\", \"D EN'Y\\x0e\", \"D EN'Y\\x0b\", \"eD EN'Y\", \"D E;N'Y\", \"D EN'Yy\", \"D EYN'Y\", \"RD EN'Y\", \"d en'y\", \"D E]N'Y\", \"D EN'Yu\", \"\\\\D EN'Y\", \"nD EN'Y\", \"D EN'Y  \", \"D EN'Y\", \"D E:N'Y\", \"DEN'Y\", \"D EN'YA\", \" D EN'Y \", \"D E\\x1dN'Y\", \"D EzN'Y\", \"D ECN'Y\", \"kD EN'Y\", \"D EN'Yn\", \"\\x10D EN'Y\", \"*D EN'Y\", \"D E(N'Y\", \"tD EN'Y\", \"\\x16D EN'Y\", \"!D EN'Y\", \"D EyN'Y\", \"pD EN'Y\", 'D EN,Y', \"6D EN'Y\", \"D EN'Y\\x7f\", \"D EN'Y@\", \"D EN'YI\", \"D EjN'Y\", \"D  EN'Y\", \"D EN'Y<\", \"D EUN'Y\", \"D EN'YR\", \"D EnN'Y\", \"D E1N'Y\", \"D E\\x1eN'Y\", \"D EN'Yd\", \"D E\\x05N'Y\", \"D EsN'Y\", \"wD EN'Y\", \"D EN'Yq\", \"D EN'YY\", \"D EN'YC\", \"XD EN'Y\", \"D EN'Y\\x08\", \"D E_N'Y\", \"?D EN'Y\", \"D EwN'Y\", \"D E\\x12N'Y\", \"D EN'Y)\", \"3D EN'Y\", \"D EN'Y]\", \"D EN'Y\\x1e\", \"D E%N'Y\", \"D E\\x0cN'Y\", \"LD EN'Y\", \"D EN'Y3\", \"\\x0fD EN'Y\", \"D E`N'Y\", \"cD EN'Y\", \"D E{N'Y\", \"D ErN'Y\", \"\\x1eD EN'Y\", \"D EN'Y\\x1c\", \"D E[N'Y\", \"D EN'Y\\x16\", \"D E~N'Y\", \"D E N'Y\", \"D EN'Y1\", \"(D EN'Y\", \"jD EN'Y\", \"D E\\nN'Y\", \"D EcN'Y\", \"D EN'Y\\x14\", \"ID EN'Y\", \"D EZN'Y\", 'D ENY', \"D EJN'Y\", \"D EN'YS\", \".D EN'Y\", \"2D EN'Y\", \"D E,N'Y\", \"\\x03D EN'Y\", \"D EN'Yg\", \"dD EN'Y\", \"D EN'YK\", \"D\\tEN'Y\", \"D EN'YO\", 'D EN´Y', \"\\rD EN'Y\", \"D EN'Y;\", \"D EGN'Y\", \"D EN'Y\\x11\", \"D ERN'Y\", \"D EuN'Y\", \"D EN'Ya\", 'D EN‟Y', \"D EN'Y%\", \"D EHN'Y\", \"\\x19D EN'Y\", \"D EN'Ye\", \"D EKN'Y\", \"D E}N'Y\", \"D EN'YT\", \"D E\\x13N'Y\", \"D EfN'Y\", 'D EN“Y', \"\\x1bD EN'Y\", 'D EN‛Y', \"D EAN'Y\", \"D EN'Y^\", \"D E/N'Y\", \"D EkN'Y\", \"D EN'Y\\x13\", \"<D EN'Y\", \"D E9N'Y\", 'D EN‘Y', \"D EN'Y[\", \"xD EN'Y\", \"D EN'Y{\", \"D E\\x06N'Y\", \"FD EN'Y\", \"\\x1fD EN'Y\", \"D E\\x17N'Y\", \"D EN'Y~\", \"D EN'Y\\n\", \"D E\\x15N'Y\", \"0D EN'Y\", \"\\x0bD EN'Y\", \"D E3N'Y\", 'D EN;Y', \"D E\\x14N'Y\", \"\\x08D EN'Y\", \"gD EN'Y\", \"D ESN'Y\", \"D EN'Yx\", \"D EN'YL\", \"D E\\tN'Y\", \"\\x11D EN'Y\", \"D EN'YQ\", \"D EFN'Y\", \"D EN'Y-\", \"D E\\xa0aN'Y\", \"D EN'Y，\", \"+D EN'Y\", \"D eN'Y\", \"D E$N'Y\", \"D ETN'Y\", \"D EN'Y\\t\", \"D E|N'Y\", \"  D EN'Y\", \"D EN'Yb\", \"D EXN'Y\", \"D EN'YG\", \"D E)N'Y\", \"D EN'Y!\", \"D E+N'Y\", \"D EN'YJ\", \"D EN'Yv\", \"\\x7fD EN'Y\", \"D E8N'Y\", \"D EN'Y\\x12\", \"D EN'Y\\x18\", \"D EN'Yz\", \"D EN'Yl\", \"D EN'Y\\x15\", \";D EN'Y\", \"D E^N'Y\", \"D EN'Y0\", \"D EQN'Y\", \"D EN'Ym\", \"D E5N'Y\", \"D EN'YF\", \"BD EN'Y\", \"D EN'Yj\", \"D EN'YE\", \"$D EN'Y\", \"D E7N'Y\", \"D E#N'Y\", \"D EpN'Y\", \"D EN'Yf\", \"D E\\x1fN'Y\", \"D EmN'Y\", \"D E\\x0bN'Y\", \"=D EN'Y\", \"\\x15D EN'Y\", \"bD EN'Y\", \"iD EN'Y\", \"D E\\x00N'Y\", \"D E\\x19N'Y\", \"\\x1dD EN'Y\", \"D EN'Yk\", \"D EN'Y:\", \"AD EN'Y\", \"D E=N'Y\", \"D EN'Ys\", \"D EN'Y(\", \"D EN'Y\\\\\", \")D EN'Y\", 'D EN=Y', \"D EN'Y\\x19\", \"D E>N'Y\", \"D EN'Y8\", \"D EN'Y\\x17\", \"D E\\x01N'Y\", \"D ElN'Y\", \"D EqN'Y\", \"D EN'YH\", '\"D EN\\'Y', \"D EN'YN\", \"D EN'Y?\", \"hD EN'Y\", \" D EN'Y\", \"D E，N'Y\", \"]D EN'Y\", \"D EN'Y.\", \"D ExN'Y\", \"D E  N'Y\", \"\\x0eD EN'Y\", \"UD EN'Y\", \"aD EN'Y\", \"D E\\\\N'Y\", \"VD EN'Y\", \"D E\\x02N'Y\", \"'D EN'Y'\", \"GD EN'Y\", \"\\nD EN'Y\", \"D EaN'Y\", \"\\x06D EN'Y\", \"\\x1aD EN'Y\", \"ZD EN'Y\", \"D EN'Y \", \"QD EN'Y\", \"D ENN'Y\", \"D EVN'Y\", 'D EN„Y', \"sD EN'Y\", \"D EN'YD\", \"PD EN'Y\", \"D E!N'Y\", \"D EN'Yo\", \"D EN'Y\\x1b\"}\n",
      "D E\"N'Y\n"
     ]
    }
   ],
   "source": [
    "l = mutate_header_value(\"D EN'Y\")\n",
    "print(l)\n",
    "print(list(l)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b17748-e824-4fde-8a69-a31c71d9edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeaderTests:\n",
    "    def __init__(self, label: str, header_name: str, alt_names: list[str], block_values: list[str], allow_values: list[str], partial_values: list[str], legacy_values: list[str], other_values: list[str], base_resp: list[tuple[str, str]]=None):\n",
    "        \"\"\"\"HeaderTests class to create lots of responses\n",
    "        label (str): Additional information about these responses (e.g., XFO)\n",
    "        header_name (str): The correct lower-case name of the header\n",
    "        alt_names (list[str]): Legacy and other (invalid) alternative header names\n",
    "        block_values (list[str]): Valid values to set the header to \"blocking\" (e.g., DENY for XFO means always disallow framing)\n",
    "        allow_values (list[str]): Valid values to set the header to \"allowing\" (e.g., unsafe-none  for COOP means do not activate COOP/always allow)\n",
    "        partial_values (list[str]): Valid values to set the header to an intermediate mode (e.g., SAMEORIGIN for XFO means allow framing only for same-origin)\n",
    "        legacy_values (list[str]): Legacy values that should not work anymore\n",
    "        other_values (list[str]): Other values we want to test as well (can include valid ones if we do not want to put too many in the other categories)\n",
    "        base_resp (list[tuple[str, str]] | None): Base response that other stuff is only added to (default None)\n",
    "        \"\"\"\n",
    "        self.label = label\n",
    "        self.header_name = header_name\n",
    "        self.alt_names = alt_names\n",
    "        self.block_values = block_values\n",
    "        self.allow_values = allow_values\n",
    "        self.partial_values = partial_values\n",
    "        self.legacy_values = legacy_values\n",
    "        self.other_values = other_values\n",
    "        self.base_resp = base_resp\n",
    "        self.responses = []\n",
    "\n",
    "    def create_response(self, header, label, status_code=200, resp_type=\"parsing\"):\n",
    "        if self.base_resp:\n",
    "            header = header + self.base_resp\n",
    "        self.responses.append((header, label, status_code, resp_type))\n",
    "\n",
    "    def save_responses(self):\n",
    "        create_count = 0\n",
    "        with Session() as session:\n",
    "            for header, label, status_code, resp_type in self.responses:\n",
    "                r, created = get_or_create(session, Response, raw_header=json.dumps(header).encode(\"utf-8\"), status_code=status_code, label=label, resp_type=resp_type)\n",
    "                if created:\n",
    "                    create_count += 1\n",
    "        print(len(self.responses))\n",
    "        print(f\"Created: {create_count}\")\n",
    "        print(self.responses[:5])\n",
    "\n",
    "    def header_name_tests(self):\n",
    "        \"\"\"Test all block, allow, partial values (correct values)\n",
    "            with the correct header names, with all alternative/legacy header names, and with mutated versions of the correct header_name\n",
    "        \"\"\"\n",
    "        for value_group in [self.block_values, self.allow_values, self.partial_values]:\n",
    "            for header_value in value_group:\n",
    "                # Original header name\n",
    "                self.create_response([(self.header_name, header_value)], self.label)\n",
    "                # Alt header names\n",
    "                for header_name in self.alt_names:\n",
    "                    self.create_response([(header_name, header_value)], self.label)\n",
    "                # Mutated header names\n",
    "                for header_name in mutate_header_name(self.header_name):\n",
    "                    self.create_response([(header_name, header_value)], self.label)\n",
    "\n",
    "    def parsing_tests(self):\n",
    "        \"\"\"Test all header values + mutated versions.\n",
    "        \"\"\"\n",
    "        # Test all legacy and other values (block, allow, partial do not have to be tested as they are already tests by header_name_tests)\n",
    "        for value_group in [self.legacy_values, self.other_values]:\n",
    "            for header_value in value_group:\n",
    "                self.create_response([(self.header_name, header_value)], self.label)\n",
    "        \n",
    "        # Mutate/change header values (block, allow, partial)\n",
    "        for value_group in [self.block_values, self.allow_values, self.partial_values]:\n",
    "            for org_header_value in value_group:\n",
    "                # Other status codes\n",
    "                for code in [201, 203, 204, 300, 302, 400, 403, 404, 418, 500]:\n",
    "                    if 300 <= code < 400:\n",
    "                        self.create_response([(self.header_name, org_header_value), redirect_empty], self.label, status_code=code)\n",
    "                    else:\n",
    "                        self.create_response([(self.header_name, org_header_value)], self.label, status_code=code)\n",
    "                # Mutated header values\n",
    "                for header_value in mutate_header_value(org_header_value):\n",
    "                    self.create_response([(self.header_name, header_value)], self.label)\n",
    "\n",
    "    def mult_headers_tests(self):\n",
    "        \"\"\"Test involving multiple headers/values\n",
    "        \"\"\"\n",
    "        all_valid_values = self.block_values + self.allow_values + self.partial_values\n",
    "        all_orders = list(permutations(all_valid_values))\n",
    "        # Basic1: all legal values in a list in all possible orders (Comma, space, semicolon-separated)\n",
    "        for order in all_orders:\n",
    "            self.create_response([(self.header_name, \", \".join(order))], self.label)\n",
    "            self.create_response([(self.header_name, \"; \".join(order))], self.label)\n",
    "            self.create_response([(self.header_name, \" \".join(order))], self.label)\n",
    "        \n",
    "        # Basic2: all legal values in separate headers in all possible orders\n",
    "        for order in all_orders:\n",
    "            headers = [(self.header_name, header_value) for header_value in order]\n",
    "            self.create_response(headers, self.label)\n",
    "        # Basic3: all legal values in both separate headers and in one header with comma?!\n",
    "        # Only if at least 3 values; split in first and all others and last and all others\n",
    "        for order in all_orders:\n",
    "            if len(order) >= 3:\n",
    "                first, rest1 = order[0], \", \".join(order[1:])\n",
    "                rest2, last = \", \".join(order[:-1]), order[-1]\n",
    "                self.create_response([(self.header_name, first), (self.header_name, rest1)], self.label)\n",
    "                self.create_response([(self.header_name, rest2), (self.header_name, last)], self.label)\n",
    "\n",
    "        # Basic4: all legal values duplicated\n",
    "        for value in all_valid_values:\n",
    "            self.create_response([(self.header_name, value), (self.header_name, value)], self.label)\n",
    "            self.create_response([(self.header_name, f\"{value}, {value}\")], self.label)\n",
    "            \n",
    "            # Could be extended with mutated versions once, e.g., X-Frame-Options: ALLOWALL, allowall;\n",
    "            # Browsers should first lowercase and then put each value in a set https://html.spec.whatwg.org/multipage/document-lifecycle.html#the-x-frame-options-header\n",
    "            # Which means no blocking should occur, if they forget the lowercasing part, the set size would be two and it would be blocked\n",
    "            # Other extensions possible as well\n",
    "            self.create_response([(self.header_name, value), (self.header_name, value.lower())], self.label)\n",
    "            self.create_response([(self.header_name, value), (self.header_name, value.upper())], self.label)\n",
    "        \n",
    "        # Advanced1: use different header names (e.g., if a browser accepts both x-frame-options and X-FRAME-OPTIONS which takes precedence?; might be neither if the browser first lower-cases or something like that)\n",
    "        # Currently only either uppercase the first header or all except the first header (other mutations and header duplication strategies could be added in the future)\n",
    "        # Could be extended with clearly invalid headers (e.g., leading or trailing space, ...)\n",
    "        for order in all_orders:\n",
    "            for (header1, header2) in [(self.header_name, self.header_name.upper()), (self.header_name.upper(), self.header_name)]:\n",
    "                # headers = [(self.header_name, header_value) for header_value in order]\n",
    "                headers = []\n",
    "                for i, header_value in enumerate(order):\n",
    "                    if i == 0:\n",
    "                        headers.append((header1, header_value))\n",
    "                    else:\n",
    "                        headers.append((header2, header_value))\n",
    "                self.create_response(headers, self.label)\n",
    "    \n",
    "        # Advanced2: use invalid values as well (e.g., a browser might always take the first header while another browser takes the first valid header?)\n",
    "        for valid_value in all_valid_values:\n",
    "            # Only use the first two invalid values (should be empty and a clearly invalid value (\"INVALID\")\n",
    "            # Could be extended with more complex approaches\n",
    "            for invalid_value in self.other_values[:2]:\n",
    "                self.create_response([(self.header_name, valid_value), (self.header_name, invalid_value)], self.label)\n",
    "                self.create_response([(self.header_name, invalid_value), (self.header_name, valid_value)], self.label)\n",
    "                self.create_response([(self.header_name, f\"{valid_value}, {invalid_value}\")], self.label)\n",
    "                self.create_response([(self.header_name, f\"{invalid_value}, {valid_value}\")], self.label)\n",
    "                \n",
    "    def create_all_tests(self):\n",
    "        self.header_name_tests()\n",
    "        self.parsing_tests()\n",
    "        self.mult_headers_tests()\n",
    "        self.save_responses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82db4649-07cd-4531-91e5-90e22c56fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeaderTestsMultHeader(HeaderTests):\n",
    "    def __init__(self, header_names, values, label, base_resp=None):\n",
    "        \"\"\"\n",
    "        header_names (list[str]): List of header names\n",
    "        values (dict[str:str]): List of list of values \n",
    "        label (str): Label of the response\n",
    "        \"\"\"\n",
    "        assert len(header_names) == len(values)\n",
    "        self.header_names = header_names\n",
    "        self.values = values\n",
    "        self.label = label\n",
    "        self.responses = []\n",
    "        self.base_resp = base_resp\n",
    "        \n",
    "    def create_all_tests(self):\n",
    "        # Test all values in all orders of headers\n",
    "        all_header_orders = list(permutations(self.header_names))\n",
    "        all_header_orders = [tuple(zip(pair, pair)) for pair in all_header_orders]\n",
    "        \n",
    "        # Mutate the header names (basic mutations only)\n",
    "        mutated_headers = []\n",
    "        for org_header in self.header_names:\n",
    "            mutated_headers.append([(org_header, header) for header in mutate_header_value(org_header, mutation_list=basic_mutations)])\n",
    "        # All possible orders of the mutated headers\n",
    "        mutated_order = [\n",
    "            tuple(product(*(mutated_headers[n] for n in list_order)))\n",
    "            for list_order in permutations(range(len(mutated_headers)))\n",
    "        ]\n",
    "        mutated_order = [item for sublist in mutated_order for item in sublist]\n",
    "        # For each header choose each value\n",
    "        for headers in mutated_order:\n",
    "        #for headers in all_header_orders: # No mutations, only the original headers\n",
    "            # Do not use all combinations of values (too many) but instead cycle through available value (pairs)\n",
    "            for i in range(len(max(self.values.values(), key=len, default=0))):\n",
    "                resp = []\n",
    "                for (org_header, header) in headers:      \n",
    "                    index = i % len(self.values[org_header]) # Safe index (cycle the list if some have more values than others)\n",
    "                    resp.append((header, self.values[org_header][index]))\n",
    "                \n",
    "                self.create_response(resp, self.label)\n",
    "        self.save_responses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f224848-3d00-4345-9881-94715386f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "redirect_empty = (\"location\", \"https://sub.headers.websec.saarland/_hp/common/empty.html\")\n",
    "site = \"sub.headers.websec.saarland\"\n",
    "origin_s = \"https://sub.headers.websec.saarland\"\n",
    "origin_s_upper = \"HTTPS://SUB.HEADERS.WEBSEC.SAARLAND\"\n",
    "origin_s_path = f\"{origin_s}/abc/\"\n",
    "origin_s_query = f\"{origin_s}/?a=a\"\n",
    "origin = \"http://sub.headers.websec.saarland\"\n",
    "origin_sp = f\"{origin_s}:443\"\n",
    "home = f\"{origin_s}/\"\n",
    "home_p = f\"{origin_sp}/\"\n",
    "parent = \"https://headers.websec.saarland\"\n",
    "child = \"https://sub.sub.headers.websec.saarland\"\n",
    "parent_childs = \"*.headers.websec.saarland\"\n",
    "self_childs = \"*.sub.headers.websec.saarland\"\n",
    "self_childs_https = \"https://*.sub.headers.websec.saarland\"\n",
    "cross_site_origin = \"https://headers.webappsec.eu\"\n",
    "all_replacements = [site, origin_s, origin_s_upper, origin_s_path, origin_s_query, origin, origin_sp, home, home_p, parent, child, parent_childs, self_childs, self_childs_https, cross_site_origin]\n",
    "URL_REP = \"<!URL!>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "080a7dbe-d7af-4f39-b9ab-47a5c8dfb2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_urls(other_values):\n",
    "    \"\"\"Use different URL, origins, sites variations if the value should allow some sites\"\"\"\n",
    "    return_values = []\n",
    "    for value in other_values:\n",
    "        if not URL_REP in value:\n",
    "            return_values.append(value)\n",
    "        else:\n",
    "            # TODO: use combinations if more than one URL in value!\n",
    "            # Only if less than 2 occurrences? Else chose a random value for each?\n",
    "\n",
    "            # Currently: replace all occurrences of URL_REP with the same url_like\n",
    "            for url_like in all_replacements:\n",
    "                return_values.append(value.replace(URL_REP, url_like))\n",
    "    return return_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c377c418-d9c7-4f63-9a24-5ca8879aeade",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"\"\n",
    "header_name = \"\"\n",
    "alt_names = []\n",
    "block_values = []\n",
    "allow_values = []\n",
    "partial_values = []\n",
    "legacy_values = []\n",
    "# Always start with the empty value and then an INVALID value (e.g., \"INVALID\"), after that both valid and invalid values can be added\n",
    "# We use the first two in `mult_headers_test`\n",
    "other_values = [\"\", \"INVALID\"]\n",
    "other_values = expand_urls(other_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c23f7b95-2ed3-4d2f-a0e6-ea27c8994b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deny, deny', 'allow-from <!URL!>; allow-from <!URL!>', 'deny, sameorigin', 'deny, allow-from <!URL!>', 'RANDOMDIRECTIVE', 'deny; deny', 'deny; allow-from <!URL!>', 'allowall', 'allow-from <!URL!>, allow-from <!URL!>', 'deny; sameorigin', 'sameorigin, allow-from <!URL!>', 'allow-from <!URL!>', 'allow-from <!URL!>, deny', 'sameorigin', 'sameorigin, deny', 'deny', 'sameorigin, sameorigin', 'sameorigin; deny', 'allow-from <!URL!>, sameorigin', 'sameorigin; sameorigin', 'allow-from <!URL!>; deny']\n",
      "\n",
      "['frame-ancestors https:;', 'frame-ancestors http:;', 'frame-ancestors <!URL!> <!URL!>;', 'frame-ancestors <!URL!>;']\n"
     ]
    }
   ],
   "source": [
    "def get_values(url, pattern):\n",
    "    content = httpx.get(url).text\n",
    "    content = content.replace(\"TESTURI\", URL_REP)\n",
    "    content = content.replace(\"http://randomorigin.com/\", URL_REP)\n",
    "    content = content.replace(\"http://randomorigin.com\", URL_REP)\n",
    "    content = content.replace(\"http://much.ninja\", URL_REP)\n",
    "    content = content.replace(\"http://random.ninja\", URL_REP)\n",
    "    content = content.replace(\"https://much.ninja\", URL_REP)\n",
    "    content = content.replace(\"http://*.ninja\", URL_REP)\n",
    "    content = content.replace(\"*.ninja\", URL_REP)\n",
    "    content = content.replace(\"much.ninja\", URL_REP)\n",
    "    matches = list(set(re.findall(pattern, content)))\n",
    "    return matches\n",
    "\n",
    "# siewert_xfo = get_values(\"https://raw.githubusercontent.com/hen95/HTTPHeaderBrowserTesting/main/transform_to_testcase.py\", r\"\\'X-Frame-Options: (.*?)\\'\")\n",
    "siewert_xfo = ['deny, deny', 'allow-from <!URL!>; allow-from <!URL!>', 'deny, sameorigin', 'deny, allow-from <!URL!>', 'RANDOMDIRECTIVE', 'deny; deny', 'deny; allow-from <!URL!>', 'allowall', 'allow-from <!URL!>, allow-from <!URL!>', 'deny; sameorigin', 'sameorigin, allow-from <!URL!>', 'allow-from <!URL!>', 'allow-from <!URL!>, deny', 'sameorigin', 'sameorigin, deny', 'deny', 'sameorigin, sameorigin', 'sameorigin; deny', 'allow-from <!URL!>, sameorigin', 'sameorigin; sameorigin', 'allow-from <!URL!>; deny']\n",
    "print(siewert_xfo)\n",
    "print()\n",
    "# siewert_csp = get_values(\"https://raw.githubusercontent.com/hen95/HTTPHeaderBrowserTesting/main/transform_to_testcase.py\", r\"\\'Content-Security-Policy: (.*?)\\'\")\n",
    "siewert_csp = ['frame-ancestors https:;', 'frame-ancestors http:;', 'frame-ancestors <!URL!> <!URL!>;', 'frame-ancestors <!URL!>;']\n",
    "print(siewert_csp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c43c069-7cd4-4ab2-9e4c-7c1845f52c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'SAMEORIGIN',\n",
       " '  SAMEORIGIN ',\n",
       " '\"SAMEORIGIN,DENY\"',\n",
       " '  SAMEORIGIN,    DENY',\n",
       " '  DENY ',\n",
       " 'ALLOWALL',\n",
       " '\"DENY\"',\n",
       " 'ALLOW-FROM <!URL!>',\n",
       " 'denY',\n",
       " '\"SAMEORIGIN\"',\n",
       " 'sameOriGin',\n",
       " 'DENY',\n",
       " ',SAMEORIGIN,,DENY,',\n",
       " 'INVALID',\n",
       " 'allowAll',\n",
       " 'sameOrigin',\n",
       " 'ALLOW-FROM=<!URL!>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_wpt_values(dir_path, pattern=r'headerValue: `(.*)`|headerValue2: `(.*)`'):\n",
    "    # Initialize a list to store matching strings\n",
    "    values = set()\n",
    "    # Use glob to find all files with the specified extension recursively\n",
    "    file_paths = glob.glob(os.path.join(dir_path, '*.html'), recursive=False)\n",
    "    # Iterate through the list of file paths\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            content = content.replace(\"https://example.com/\", URL_REP)\n",
    "            matches = re.findall(pattern, content)\n",
    "            for match1, match2 in matches:\n",
    "                values.add(match1)\n",
    "                values.add(match2)\n",
    "    return list(values)\n",
    "\n",
    "#wpt_xfo = get_wpt_values('../../../x-frame-options/') # We removed all unrelated WPT folders; to rerun clone the original WPT repo and set the correct path\n",
    "wpt_xfo = ['', 'SAMEORIGIN', '  SAMEORIGIN ', '\"SAMEORIGIN,DENY\"', '  SAMEORIGIN,    DENY', '  DENY ', 'ALLOWALL', '\"DENY\"', 'ALLOW-FROM <!URL!>', 'denY', '\"SAMEORIGIN\"', 'sameOriGin', 'DENY', ',SAMEORIGIN,,DENY,', 'INVALID', 'allowAll', 'sameOrigin', 'ALLOW-FROM=<!URL!>']\n",
    "wpt_xfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b66ad0ae-e65e-4096-9cab-25dcb5b79842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296\n",
      "2919\n"
     ]
    }
   ],
   "source": [
    "def limit_url_occurrences(input_string, max_occurrences):\n",
    "    # Define the pattern to match <!URL!>\n",
    "    url_pattern = re.compile(rf'{URL_REP}(?:(\\s|,)*(ALLOW-FROM )?(allow-from )?{URL_REP})+')\n",
    "    #url_pattern = re.compile(rf'{URL_REP}(?:(\\s|,)*{URL_REP})+')\n",
    "\n",
    "    # Find all consecutive occurrences of <!URL!>\n",
    "    consecutive_url_matches = url_pattern.findall(input_string)\n",
    "\n",
    "    # Calculate the number of replacements needed\n",
    "    replacements_needed = max(0, len(consecutive_url_matches) - max_occurrences)\n",
    "\n",
    "    # Replace excess consecutive occurrences with <!URL!>\n",
    "    replaced_string = url_pattern.sub('', input_string, count=replacements_needed)\n",
    "\n",
    "    return replaced_string\n",
    "\n",
    "\n",
    "def replace_multiple_urls(input_string):\n",
    "    # Define the pattern to match three or more consecutive <!URL!>\n",
    "    url_pattern = re.compile(r'((<!URL!>\\s*){3,})')\n",
    "\n",
    "    # Replace three or more consecutive <!URL!> with a single <!URL!>\n",
    "    replaced_string = re.sub(url_pattern, '<!URL!> ', input_string)\n",
    "\n",
    "    return replaced_string\n",
    "\n",
    "\n",
    "def run_replacements(input_string):\n",
    "    input_string = replace_multiple_urls(input_string)\n",
    "    input_string = limit_url_occurrences(input_string, 4)\n",
    "    input_string = re.sub(\"sha256-\\S+\", \"sha256-default\", input_string)\n",
    "    # Replace 4 digit numbers and higher with 60 (for HSTS; should not affect other headers?)\n",
    "    input_string = re.sub(\"\\d{4,}\", \"60\", input_string)\n",
    "    return input_string\n",
    "\n",
    "def get_crawler_values(url, min_count=0):\n",
    "    if \"https://\" in url:\n",
    "        content = httpx.get(url).text\n",
    "        content = re.sub(r\"(http(s)?|HTTP(S)?)://[\\w.*/\\-:?=]*|([\\w*\\-/]+\\.)+[\\w*\\-:/?=]+\", URL_REP, content)\n",
    "        rows = [row.rsplit(\" \", maxsplit=1) for row in content.split(\"\\r\\n\")[1:] if \" \" in row]\n",
    "    else:\n",
    "        content = open(url, 'r', encoding='utf-8', errors=\"backslashreplace\").read()\n",
    "        content = re.sub(r\"(http(s)?|HTTP(S)?)://[\\w.*/\\-:?=]*|([\\w*\\-/]+\\.)+[\\w*\\-:/?=]+\", URL_REP, content)\n",
    "        rows = [row.rsplit(\" \", maxsplit=1) for row in content.split(\"\\n\")[1:] if \" \" in row]\n",
    "    # Only use values occuring more than once? Otherwise we have to many possible values?\n",
    "    filtered_rows = []\n",
    "    for row in rows:\n",
    "        try:\n",
    "            if int(row[1].replace(\",\", \"\")) >= min_count:\n",
    "                filtered_rows.append(row[0])\n",
    "        except (ValueError, IndexError):\n",
    "            # Ignore rows that cause errors\n",
    "            pass\n",
    "    return list(set([run_replacements(row) for row in filtered_rows]))\n",
    "\n",
    "#crawler_ninja_xfo = get_crawler_values(\"https://crawler.ninja/files/xfo-values.txt\")\n",
    "crawler_ninja_xfo = get_crawler_values(\"cached_crawler-ninja_values/xfo-values.txt\")\n",
    "print(len(crawler_ninja_xfo))\n",
    "#display(crawler_ninja_xfo)\n",
    "#crawler_ninja_csp = get_crawler_values(\"https://crawler.ninja/files/csp-values.txt\", min_count=2)\n",
    "crawler_ninja_csp = get_crawler_values(\"cached_crawler-ninja_values/csp-values.txt\", min_count=2)\n",
    "print(len(crawler_ninja_csp))\n",
    "#crawler_ninja_csp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29ec5b14-cafe-4c08-aae5-ae2aa47c0382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4705\n",
      "Created: 4596\n",
      "[([('x-frame-options', 'DENY')], 'XFO', 200, 'parsing'), ([('frame-options', 'DENY')], 'XFO', 200, 'parsing'), ([('x-frame-option', 'DENY')], 'XFO', 200, 'parsing'), ([('x-frames-options', 'DENY')], 'XFO', 200, 'parsing'), ([('content-security-policy', 'DENY')], 'XFO', 200, 'parsing')]\n"
     ]
    }
   ],
   "source": [
    "label = \"XFO\"\n",
    "header_name = \"x-frame-options\"\n",
    "alt_names = [\"frame-options\", \"x-frame-option\", \"x-frames-options\", \"content-security-policy\", \"x_frame_options\", \"xframeoptions\"]\n",
    "block_values = [\"DENY\"]\n",
    "allow_values = [\"ALLOWALL\"] # This value does not really exist but has some special meaning for processing multiple values (https://html.spec.whatwg.org/multipage/document-lifecycle.html#the-x-frame-options-header)\n",
    "partial_values = [\"SAMEORIGIN\"]\n",
    "legacy_values = [f\"ALLOW-FROM {origin_s}\"]\n",
    "\n",
    "# Always start with the empty value and then an INVALID value (e.g., \"INVALID\"), after that both valid and invalid values can be added\n",
    "# We use the first two in `mult_headers_test`\n",
    "basic_values = [\"\", \"INVALID\", \"null\", \"*\", URL_REP]\n",
    "# https://wpt.fyi/results/x-frame-options?label=master&label=experimental&aligned&q=x-frame\n",
    "wpt_values = ['', 'SAMEORIGIN', '  SAMEORIGIN ', '\"SAMEORIGIN,DENY\"', '  SAMEORIGIN,    DENY', '  DENY ', 'ALLOWALL', '\"DENY\"', 'ALLOW-FROM <!URL!>', 'denY', '\"SAMEORIGIN\"', 'sameOriGin', 'DENY', ',SAMEORIGIN,,DENY,', 'INVALID', 'allowAll', 'sameOrigin', 'ALLOW-FROM=<!URL!>']\n",
    "# https://github.com/hen95/HTTPHeaderBrowserTesting\n",
    "siewert_values = ['deny, deny', 'allow-from <!URL!>; allow-from <!URL!>', 'deny, sameorigin', 'deny, allow-from <!URL!>', 'RANDOMDIRECTIVE', 'deny; deny', 'deny; allow-from <!URL!>', 'allowall', 'allow-from <!URL!>, allow-from <!URL!>', 'deny; sameorigin', 'sameorigin, allow-from <!URL!>', 'allow-from <!URL!>', 'allow-from <!URL!>, deny', 'sameorigin', 'sameorigin, deny', 'deny', 'sameorigin, sameorigin', 'sameorigin; deny', 'allow-from <!URL!>, sameorigin', 'sameorigin; sameorigin', 'allow-from <!URL!>; deny']\n",
    "# https://crawler.ninja/files/xfo-values.txt\n",
    "#crawler_ninja_values = get_crawler_values(\"https://crawler.ninja/files/xfo-values.txt\")\n",
    "crawler_ninja_values = get_crawler_values(\"cached_crawler-ninja_values/xfo-values.txt\")\n",
    "own_values = []\n",
    "other_values = basic_values + wpt_values + siewert_values + crawler_ninja_values + own_values\n",
    "other_values = expand_urls(other_values)\n",
    "xfo_all = block_values + allow_values + partial_values + legacy_values + other_values\n",
    "ht = HeaderTests(label, header_name, alt_names, block_values, allow_values, partial_values, legacy_values, other_values)\n",
    "ht.create_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d1e3c80-722d-4061-948f-ab0fba870175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2759\n",
      "Created: 2744\n",
      "[([('content-security-policy', \"frame-ancestors 'none'\")], 'CSP-FA', 200, 'parsing'), ([('x-content-security-policy', \"frame-ancestors 'none'\")], 'CSP-FA', 200, 'parsing'), ([('x-webkit-csp', \"frame-ancestors 'none'\")], 'CSP-FA', 200, 'parsing'), ([('x-webkit-content-security-policy', \"frame-ancestors 'none'\")], 'CSP-FA', 200, 'parsing'), ([('content-sec0urity-policy', \"frame-ancestors 'none'\")], 'CSP-FA', 200, 'parsing')]\n"
     ]
    }
   ],
   "source": [
    "label = \"CSP-FA\"\n",
    "header_name = \"content-security-policy\"\n",
    "alt_names = [\"x-content-security-policy\", \"x-webkit-csp\", \"x-webkit-content-security-policy\"]\n",
    "block_values = [\"frame-ancestors 'none'\"]\n",
    "allow_values = [\"frame-ancestors *\"]\n",
    "partial_values = [\"frame-ancestors 'self'\"]\n",
    "legacy_values = []\n",
    "# Always start with the empty value and then an INVALID value (e.g., \"INVALID\"), after that both valid and invalid values can be added\n",
    "# We use the first two in `mult_headers_test`\n",
    "basic_values = [\"\", \"INVALID\", \"null\", \"*\", URL_REP]\n",
    "# https://wpt.fyi/results/content-security-policy/frame-ancestors?label=master&label=experimental&aligned&q=frame\n",
    "wpt_values = [\"frame-ancestors 'none'\", \"frame-ancestors 'self'\", \"frame-ancestors *\", f\"frame-ancestors {URL_REP}\"]\n",
    "# https://github.com/hen95/HTTPHeaderBrowserTesting\n",
    "# siewert_values = get_values(\"https://raw.githubusercontent.com/hen95/HTTPHeaderBrowserTesting/main/transform_to_testcase.py\", r\"\\'Content-Security-Policy: (.*?)\\'\")\n",
    "siewert_values = ['frame-ancestors https:;', 'frame-ancestors http:;', 'frame-ancestors <!URL!> <!URL!>;', 'frame-ancestors <!URL!>;']\n",
    "\n",
    "# https://crawler.ninja/files/csp-values.txt\n",
    "crawler_ninja_values = []\n",
    "# Note: add crawler_ninja_values, Problem: Too many? Many are very similar and URL replacement results in a massive number of values\n",
    "# crawler_ninja_values = get_crawler_values(\"https://crawler.ninja/files/csp-values.txt\", min_count=2)\n",
    "# crawler_ninja_values = get_crawler_values(\"cached_crawler-ninja_values/csp-values.txt\", min_count=2)\n",
    "\n",
    "own_values = [\"default-src 'none'\", \"self\", \"*\", \"frame-ancestors self\", \"frame-ancestors\", \"frame-ancestors none\", \"frame-src none\", \"frame-ancestors 'null'\", \"frame-ancestors null\"]\n",
    "other_values = basic_values + wpt_values + siewert_values + crawler_ninja_values + own_values\n",
    "other_values = expand_urls(other_values)\n",
    "csp_fa_all = block_values + allow_values + partial_values + legacy_values + other_values\n",
    "ht = HeaderTests(label, header_name, alt_names, block_values, allow_values, partial_values, legacy_values, other_values)\n",
    "ht.create_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcf2bf9c-fe7a-40bc-8570-dae9f6a9d92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2480\n",
      "Created: 2465\n",
      "[([('access-control-allow-origin', 'null'), ('Test', 'Test'), ('access-control-allow-credentials', 'true'), ('access-control-allow-methods', 'TEST'), ('access-control-allow-headers', 'Test'), ('access-control-expose-headers', 'Test')], 'CORS-ACAO', 200, 'parsing'), ([('access-contro4l-allow-origin', 'null'), ('Test', 'Test'), ('access-control-allow-credentials', 'true'), ('access-control-allow-methods', 'TEST'), ('access-control-allow-headers', 'Test'), ('access-control-expose-headers', 'Test')], 'CORS-ACAO', 200, 'parsing'), ([('access-contro$l-allow-origin', 'null'), ('Test', 'Test'), ('access-control-allow-credentials', 'true'), ('access-control-allow-methods', 'TEST'), ('access-control-allow-headers', 'Test'), ('access-control-expose-headers', 'Test')], 'CORS-ACAO', 200, 'parsing'), ([('access-control-allow-origin`', 'null'), ('Test', 'Test'), ('access-control-allow-credentials', 'true'), ('access-control-allow-methods', 'TEST'), ('access-control-allow-headers', 'Test'), ('access-control-expose-headers', 'Test')], 'CORS-ACAO', 200, 'parsing'), ([('access-control-allow-originV', 'null'), ('Test', 'Test'), ('access-control-allow-credentials', 'true'), ('access-control-allow-methods', 'TEST'), ('access-control-allow-headers', 'Test'), ('access-control-expose-headers', 'Test')], 'CORS-ACAO', 200, 'parsing')]\n",
      "874\n",
      "Created: 864\n",
      "[([('access-control-allow-credentials', 'true'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-methods', 'TEST'), ('access-control-allow-headers', 'Test'), ('access-control-expose-headers', 'Test')], 'CORS-ACAC', 200, 'parsing'), ([('access-control-allow-credentials0', 'true'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-methods', 'TEST'), ('access-control-allow-headers', 'Test'), ('access-control-expose-headers', 'Test')], 'CORS-ACAC', 200, 'parsing'), ([('access-control-a\\x19llow-credentials', 'true'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-methods', 'TEST'), ('access-control-allow-headers', 'Test'), ('access-control-expose-headers', 'Test')], 'CORS-ACAC', 200, 'parsing'), ([('access-control-a\\x06llow-credentials', 'true'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-methods', 'TEST'), ('access-control-allow-headers', 'Test'), ('access-control-expose-headers', 'Test')], 'CORS-ACAC', 200, 'parsing'), ([('access-control-amllow-credentials', 'true'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-methods', 'TEST'), ('access-control-allow-headers', 'Test'), ('access-control-expose-headers', 'Test')], 'CORS-ACAC', 200, 'parsing')]\n",
      "1586\n",
      "Created: 1576\n",
      "[([('access-control-allow-methods', '*'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-credentials', 'true'), ('access-control-allow-headers', 'Test'), ('access-control-expose-headers', 'Test')], 'CORS-ACAM', 200, 'parsing'), ([(',access-control-allow-methods', '*'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-credentials', 'true'), ('access-control-allow-headers', 'Test'), ('access-control-expose-headers', 'Test')], 'CORS-ACAM', 200, 'parsing'), ([('access-controlv-allow-methods', '*'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-credentials', 'true'), ('access-control-allow-headers', 'Test'), ('access-control-expose-headers', 'Test')], 'CORS-ACAM', 200, 'parsing'), ([('access-control-allow-methodsN', '*'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-credentials', 'true'), ('access-control-allow-headers', 'Test'), ('access-control-expose-headers', 'Test')], 'CORS-ACAM', 200, 'parsing'), ([('access‛control‛allow‛methods', '*'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-credentials', 'true'), ('access-control-allow-headers', 'Test'), ('access-control-expose-headers', 'Test')], 'CORS-ACAM', 200, 'parsing')]\n",
      "1587\n",
      "Created: 1577\n",
      "[([('access-control-allow-headers', '*'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-credentials', 'true'), ('access-control-allow-methods', 'TEST'), ('access-control-expose-headers', 'Test')], 'CORS-ACAH', 200, 'parsing'), ([('access-control\\x12-allow-headers', '*'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-credentials', 'true'), ('access-control-allow-methods', 'TEST'), ('access-control-expose-headers', 'Test')], 'CORS-ACAH', 200, 'parsing'), ([('access-control@-allow-headers', '*'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-credentials', 'true'), ('access-control-allow-methods', 'TEST'), ('access-control-expose-headers', 'Test')], 'CORS-ACAH', 200, 'parsing'), ([('Naccess-control-allow-headers', '*'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-credentials', 'true'), ('access-control-allow-methods', 'TEST'), ('access-control-expose-headers', 'Test')], 'CORS-ACAH', 200, 'parsing'), ([('access-controlE-allow-headers', '*'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-credentials', 'true'), ('access-control-allow-methods', 'TEST'), ('access-control-expose-headers', 'Test')], 'CORS-ACAH', 200, 'parsing')]\n",
      "1587\n",
      "Created: 1577\n",
      "[([('access-control-expose-headers', '*'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-credentials', 'true'), ('access-control-allow-methods', 'TEST'), ('access-control-allow-headers', 'Test')], 'CORS-ACEH', 200, 'parsing'), ([('access-control\\x1c-expose-headers', '*'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-credentials', 'true'), ('access-control-allow-methods', 'TEST'), ('access-control-allow-headers', 'Test')], 'CORS-ACEH', 200, 'parsing'), ([('access-controli-expose-headers', '*'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-credentials', 'true'), ('access-control-allow-methods', 'TEST'), ('access-control-allow-headers', 'Test')], 'CORS-ACEH', 200, 'parsing'), ([('access-control\\x01-expose-headers', '*'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-credentials', 'true'), ('access-control-allow-methods', 'TEST'), ('access-control-allow-headers', 'Test')], 'CORS-ACEH', 200, 'parsing'), ([('access-control-expose-headers,', '*'), ('Test', 'Test'), ('access-control-allow-origin', 'https://sub.headers.websec.saarland'), ('access-control-allow-credentials', 'true'), ('access-control-allow-methods', 'TEST'), ('access-control-allow-headers', 'Test')], 'CORS-ACEH', 200, 'parsing')]\n"
     ]
    }
   ],
   "source": [
    "# CORS: fixate all header except one, only mutate/rotate this one header\n",
    "\n",
    "# https://wpt.fyi/results/cors?label=master&label=experimental&aligned&q=cors\n",
    "wpt_values = [] # Nothing parsing related?\n",
    "# https://github.com/hen95/HTTPHeaderBrowserTesting\n",
    "siewert_values = [] # Difficult to extract\n",
    "# https://crawler.ninja/files/acao-values.txt\n",
    "crawler_ninja_values = [] # Only ACAO and mostly different origins\n",
    "\n",
    "label = \"CORS\"\n",
    "alt_names = []\n",
    "full_base_resp = [(\"Test\", \"Test\"), (\"access-control-allow-origin\", origin_s), (\"access-control-allow-credentials\", \"true\"), (\"access-control-allow-methods\", \"TEST\"), (\"access-control-allow-headers\", \"Test\"), (\"access-control-expose-headers\", \"Test\")]\n",
    "\n",
    "\n",
    "# ACAO\n",
    "label = \"CORS-ACAO\"\n",
    "header_name = \"access-control-allow-origin\"\n",
    "base_resp = [tup for tup in full_base_resp if tup[0] != header_name]\n",
    "block_values = [\"null\"]\n",
    "allow_values = [\"*\"] \n",
    "partial_values = [origin_s]\n",
    "legacy_values = []\n",
    "basic_values = [\"\", \"INVALID\", \"null\", \"*\", \"Test\", \"true\", \"?1\", \"?0\", \"TEST\", \"test\", \"false\", \"https://\", \"//\", URL_REP]\n",
    "other_values = expand_urls(basic_values)\n",
    "ht = HeaderTests(label, header_name, alt_names, block_values, allow_values, partial_values, legacy_values, other_values, base_resp)\n",
    "ht.create_all_tests()\n",
    "\n",
    "# ACAC\n",
    "label = \"CORS-ACAC\"\n",
    "header_name = \"access-control-allow-credentials\"\n",
    "base_resp = [tup for tup in full_base_resp if tup[0] != header_name]\n",
    "block_values = []\n",
    "allow_values = [\"true\"] \n",
    "partial_values = []\n",
    "legacy_values = []\n",
    "basic_values = [\"\", \"INVALID\", \"null\", \"*\", \"Test\", \"true\", \"?1\", \"?0\", \"TEST\", \"test\", \"false\", \"https://\", \"//\", URL_REP]\n",
    "other_values = expand_urls(basic_values)\n",
    "ht = HeaderTests(label, header_name, alt_names, block_values, allow_values, partial_values, legacy_values, other_values, base_resp)\n",
    "ht.create_all_tests()\n",
    "\n",
    "# ACAM, ACAH, ACEH\n",
    "for header_name in [\"access-control-allow-methods\", \"access-control-allow-headers\", \"access-control-expose-headers\"]:\n",
    "    label = f\"CORS-{''.join([h[0].upper() for h in header_name.split('-')])}\"\n",
    "    base_resp = [tup for tup in full_base_resp if tup[0] != header_name]\n",
    "    block_values = []\n",
    "    allow_values = [\"*\"] \n",
    "    if \"methods\" in header_name:\n",
    "        partial_values = [\"TEST\"]\n",
    "    else:\n",
    "        partial_values = [\"Test\"]\n",
    "    legacy_values = []\n",
    "    basic_values = [\"\", \"INVALID\", \"null\", \"*\", \"Test\", \"true\", \"?1\", \"?0\", \"TEST\", \"test\", \"false\", \"https://\", \"//\", URL_REP]\n",
    "    other_values = expand_urls(basic_values)\n",
    "    ht = HeaderTests(label, header_name, alt_names, block_values, allow_values, partial_values, legacy_values, other_values, base_resp)\n",
    "    ht.create_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a5ed7a9-1bdd-403d-8fb6-dcefa4a40596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3393\n",
      "Created: 3357\n",
      "[([('cross-origin-resource-policy', '')], 'CORP', 200, 'parsing'), ([('from-origin', '')], 'CORP', 200, 'parsing'), ([('x-cross-origin-resource-policy', '')], 'CORP', 200, 'parsing'), ([('cross-origin-resource-policyQ', '')], 'CORP', 200, 'parsing'), ([('cross-origin-resource-policy\\x0f', '')], 'CORP', 200, 'parsing')]\n"
     ]
    }
   ],
   "source": [
    "label = \"CORP\"\n",
    "header_name = \"cross-origin-resource-policy\"\n",
    "alt_names = [\"from-origin\", \"x-cross-origin-resource-policy\"]\n",
    "block_values = [\"\"]\n",
    "allow_values = [\"cross-origin\"]\n",
    "partial_values = [\"same-site\", \"same-origin\"]\n",
    "legacy_values = []\n",
    "# Always start with the empty value and then an INVALID value (e.g., \"INVALID\"), after that both valid and invalid values can be added\n",
    "# We use the first two in `mult_headers_test`\n",
    "basic_values = [\"\", \"INVALID\", \"null\", \"*\", URL_REP]\n",
    "# https://wpt.fyi/results/fetch/cross-origin-resource-policy?label=master&label=experimental&aligned&q=cross-origin-resource-policy\n",
    "wpt_values = [\"same\", \"same, same-origin\", \"SAME-ORIGIN\", \"Same-Origin\", \"same-origin, <>\", \"same-origin, same-origin\", URL_REP]\n",
    "# https://github.com/hen95/HTTPHeaderBrowserTesting\n",
    "siewert_values = [] # No CORP tested\n",
    "# https://crawler.ninja/files\n",
    "crawler_ninja_values = [] # No CORP tested\n",
    "own_values = [\"unsafe-none\"]\n",
    "other_values = basic_values + wpt_values + siewert_values + crawler_ninja_values + own_values\n",
    "other_values = expand_urls(other_values)\n",
    "ht = HeaderTests(label, header_name, alt_names, block_values, allow_values, partial_values, legacy_values, other_values)\n",
    "ht.create_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a73e9aa2-c2be-4a45-bdd0-fe517c4b1fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2650\n",
      "Created: 2637\n",
      "[([('cross-origin-embedder-policy', 'require-corp')], 'COEP', 200, 'parsing'), ([('x-cross-origin-embedder-policy', 'require-corp')], 'COEP', 200, 'parsing'), ([('=cross-origin-embedder-policy', 'require-corp')], 'COEP', 200, 'parsing'), ([('cross-origin-eembedder-policy', 'require-corp')], 'COEP', 200, 'parsing'), ([('cross-origin-embedder-policy\\x0f', 'require-corp')], 'COEP', 200, 'parsing')]\n"
     ]
    }
   ],
   "source": [
    "label = \"COEP\"\n",
    "header_name = \"cross-origin-embedder-policy\"\n",
    "alt_names = [\"x-cross-origin-embedder-policy\"]\n",
    "block_values = [\"require-corp\"]\n",
    "allow_values = [\"unsafe-none\"]\n",
    "partial_values = [\"credentialless\"]\n",
    "legacy_values = []\n",
    "# Always start with the empty value and then an INVALID value (e.g., \"INVALID\"), after that both valid and invalid values can be added\n",
    "# We use the first two in `mult_headers_test`\n",
    "basic_values = [\"\", \"INVALID\", \"null\", \"*\", URL_REP]\n",
    "# https://wpt.fyi/results/html/cross-origin-embedder-policy?label=master&label=experimental&aligned&q=cross-origin-embedder-policy\n",
    "wpt_values =   ['jibberish', 'require%FFcorp', 'require-corp;', '\\u000brequire-corp\\u000b', '\\u000crequire-corp\\u000c', '\\u000drequire-corp\\u000d', 'Require-corp', '\"require-corp\"', ':cmVxdWlyZS1jb3Jw:', 'require-corp;\\tfoo=bar', 'require-corp require-corp', 'require-corp,require-corp', 'require-corp', ' require-corp ', '\\trequire-corp\\t', ' \\trequire-corp', 'require-corp\\t ', 'require-corp; foo=bar', 'require-corp;require-corp', 'require-corp; report-to=\"data:']\n",
    "# https://github.com/hen95/HTTPHeaderBrowserTesting\n",
    "siewert_values = [] # No COEP tested\n",
    "# https://crawler.ninja/files\n",
    "crawler_ninja_values = [] # No COEP tested\n",
    "own_values = [\"cross-origin\", \"same-origin\"]\n",
    "other_values = basic_values + wpt_values + siewert_values + crawler_ninja_values + own_values\n",
    "other_values = expand_urls(other_values)\n",
    "ht = HeaderTests(label, header_name, alt_names, block_values, allow_values, partial_values, legacy_values, other_values)\n",
    "ht.create_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c867e2c8-8dd6-43a2-b49f-c06b1886922d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2673\n",
      "Created: 2656\n",
      "[([('cross-origin-opener-policy', 'unsafe-none')], 'COOP', 200, 'parsing'), ([('x-cross-origin-opener-policy', 'unsafe-none')], 'COOP', 200, 'parsing'), ([('cross‟origin‟opener‟policy', 'unsafe-none')], 'COOP', 200, 'parsing'), ([('cross-origin-opener-policyX', 'unsafe-none')], 'COOP', 200, 'parsing'), ([('bcross-origin-opener-policy', 'unsafe-none')], 'COOP', 200, 'parsing')]\n"
     ]
    }
   ],
   "source": [
    "label = \"COOP\"\n",
    "header_name = \"cross-origin-opener-policy\"\n",
    "alt_names = [\"x-cross-origin-opener-policy\"]\n",
    "block_values = []\n",
    "allow_values = [\"unsafe-none\"]\n",
    "partial_values = [\"same-origin\", \"same-origin-allow-popups\"]\n",
    "legacy_values = []\n",
    "# Always start with the empty value and then an INVALID value (e.g., \"INVALID\"), after that both valid and invalid values can be added\n",
    "# We use the first two in `mult_headers_test`\n",
    "basic_values = [\"\", \"INVALID\", \"null\", \"*\", URL_REP]\n",
    "# https://wpt.fyi/results/html/cross-origin-opener-policy?label=master&label=experimental&aligned&q=cross-origin-opener-policy\n",
    "wpt_values =   [\"same-origin;\", \"\\u000bsame-origin\\u000b\", \"\\u000csame-origin\\u000c\", \"\\u000dsame-origin\\u000d\", \"Same-origin\", \"same-origin;\\tfoo=bar\", \"same-origin ;foo=bar\", \"same-origin; foo=bar;\", \"\\\"same-origin\\\"\", \":c2FtZS1vcmlnaW4=:\", \"?1\", \"1\", \"$same-origin\",  \"same-origin same-origin\", \"same-origin\\\\,same-origin\", \"*same-origin \", \"same%FForigin\", \" same-origin\", \"same-origin \", \"\\tsame-origin\", \"same-origin\\t\", \"same-origin;same-origin\", \"same-origin; foo=bar\"]\n",
    "# https://github.com/hen95/HTTPHeaderBrowserTesting\n",
    "siewert_values = [] # No COOP tested\n",
    "# https://crawler.ninja/files\n",
    "crawler_ninja_values = [] # No COOP tested\n",
    "own_values = [\"cross-origin\", \"same-origin\", \"same-origin-plus-COEP\"]\n",
    "other_values = basic_values + wpt_values + siewert_values + crawler_ninja_values + own_values\n",
    "other_values = expand_urls(other_values)\n",
    "ht = HeaderTests(label, header_name, alt_names, block_values, allow_values, partial_values, legacy_values, other_values)\n",
    "ht.create_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "daa1f685-d628-42b7-8a61-ade8b4d50190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2739\n",
      "Created: 2726\n",
      "[([('content-security-policy', \"script-src 'none'\")], 'CSP-SCRIPT', 200, 'parsing'), ([('x-content-security-policy', \"script-src 'none'\")], 'CSP-SCRIPT', 200, 'parsing'), ([('x-webkit-csp', \"script-src 'none'\")], 'CSP-SCRIPT', 200, 'parsing'), ([('x-webkit-content-security-policy', \"script-src 'none'\")], 'CSP-SCRIPT', 200, 'parsing'), ([('content-sec0urity-policy', \"script-src 'none'\")], 'CSP-SCRIPT', 200, 'parsing')]\n"
     ]
    }
   ],
   "source": [
    "label = \"CSP-SCRIPT\"\n",
    "header_name = \"content-security-policy\"\n",
    "alt_names = [\"x-content-security-policy\", \"x-webkit-csp\", \"x-webkit-content-security-policy\"]\n",
    "block_values = [\"script-src 'none'\"]\n",
    "allow_values = [\"script-src *\"]\n",
    "partial_values = [\"script-src 'self'\"]\n",
    "legacy_values = []\n",
    "# Always start with the empty value and then an INVALID value (e.g., \"INVALID\"), after that both valid and invalid values can be added\n",
    "# We use the first two in `mult_headers_test`\n",
    "basic_values = [\"\", \"INVALID\", \"null\", \"*\", URL_REP]\n",
    "# https://wpt.fyi/results/content-security-policy?label=master&label=experimental&aligned&q=script-src\n",
    "wpt_values = [] # Tests are more related to correct ordering and co and not parsing?\n",
    "# https://github.com/hen95/HTTPHeaderBrowserTesting\n",
    "siewert_values = [] # not tested\n",
    "# https://crawler.ninja/files/csp-values.txt\n",
    "crawler_ninja_values = []\n",
    "# NOTE: maybe add crawler_ninja_values, Problem: Too many? Many are very similar and URL replacement results in a massive number of values\n",
    "# crawler_ninja_values = get_crawler_values(\"https://crawler.ninja/files/csp-values.txt\")\n",
    "own_values = [\"default-src 'none'\", \"self\", \"*\", \"script-src self\", \"script-src\", \"script-src none\", \"script-src none\", \"script-src 'null'\", \"script-src null\", f\"script-src-elem {URL_REP}\", f\"script-src-attr {URL_REP}\"]\n",
    "other_values = basic_values + wpt_values + siewert_values + crawler_ninja_values + own_values\n",
    "other_values = expand_urls(other_values)\n",
    "ht = HeaderTests(label, header_name, alt_names, block_values, allow_values, partial_values, legacy_values, other_values)\n",
    "ht.create_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "34fca1f2-9d82-40e4-b66b-79afb9e79ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2725\n",
      "Created: 2710\n",
      "[([('content-security-policy', \"img-src 'none'\")], 'CSP-IMG', 200, 'parsing'), ([('x-content-security-policy', \"img-src 'none'\")], 'CSP-IMG', 200, 'parsing'), ([('x-webkit-csp', \"img-src 'none'\")], 'CSP-IMG', 200, 'parsing'), ([('x-webkit-content-security-policy', \"img-src 'none'\")], 'CSP-IMG', 200, 'parsing'), ([('content-sec0urity-policy', \"img-src 'none'\")], 'CSP-IMG', 200, 'parsing')]\n"
     ]
    }
   ],
   "source": [
    "label = \"CSP-IMG\"\n",
    "header_name = \"content-security-policy\"\n",
    "alt_names = [\"x-content-security-policy\", \"x-webkit-csp\", \"x-webkit-content-security-policy\"]\n",
    "block_values = [\"img-src 'none'\"]\n",
    "allow_values = [\"img-src *\"]\n",
    "partial_values = [\"img-src 'self'\"]\n",
    "legacy_values = []\n",
    "# Always start with the empty value and then an INVALID value (e.g., \"INVALID\"), after that both valid and invalid values can be added\n",
    "# We use the first two in `mult_headers_test`\n",
    "basic_values = [\"\", \"INVALID\", \"null\", \"*\", URL_REP]\n",
    "# https://wpt.fyi/results/content-security-policy?label=master&label=experimental&aligned&q=img-src\n",
    "wpt_values = [\"img-src 'none'\", \"img-src 'self'\", \"img-src *\", f\"img-src {URL_REP}\"]\n",
    "# https://github.com/hen95/HTTPHeaderBrowserTesting\n",
    "siewert_values = [] # Not tested\n",
    "# https://crawler.ninja/files/csp-values.txt\n",
    "crawler_ninja_values = []\n",
    "# NOTE: maybe add crawler_ninja_values, Problem: Too many? Many are very similar and URL replacement results in a massive number of values\n",
    "# crawler_ninja_values = get_crawler_values(\"https://crawler.ninja/files/csp-values.txt\")\n",
    "own_values = [\"default-src 'none'\", \"self\", \"*\", \"img-src self\", \"img-src\", \"img-src none\", \"frame-src none\", \"img-src 'null'\", \"img-src null\"]\n",
    "other_values = basic_values + wpt_values + siewert_values + crawler_ninja_values + own_values\n",
    "other_values = expand_urls(other_values)\n",
    "ht = HeaderTests(label, header_name, alt_names, block_values, allow_values, partial_values, legacy_values, other_values)\n",
    "ht.create_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3126c2a9-10ae-43f7-8474-9a1414d96618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3355\n",
      "Created: 3324\n",
      "[([('strict-transport-security', 'max-age=0')], 'HSTS', 200, 'parsing'), ([('x-strict-transport-security', 'max-age=0')], 'HSTS', 200, 'parsing'), ([('hsts', 'max-age=0')], 'HSTS', 200, 'parsing'), ([('%strict-transport-security', 'max-age=0')], 'HSTS', 200, 'parsing'), ([('strict-trans.port-security', 'max-age=0')], 'HSTS', 200, 'parsing')]\n"
     ]
    }
   ],
   "source": [
    "label = \"HSTS\"\n",
    "header_name = \"strict-transport-security\"\n",
    "alt_names = [\"x-strict-transport-security\", \"hsts\"]\n",
    "block_values = [\"max-age=0\"]\n",
    "allow_values = []\n",
    "partial_values = [\"max-age=60\", \"max-age=20; includeSubDomains\"]\n",
    "legacy_values = []\n",
    "# Always start with the empty value and then an INVALID value (e.g., \"INVALID\"), after that both valid and invalid values can be added\n",
    "# We use the first two in `mult_headers_test`\n",
    "basic_values = [\"\", \"INVALID\", \"null\", \"*\", URL_REP]\n",
    "# Not in WPT\n",
    "wpt_values = []\n",
    "# https://github.com/hen95/HTTPHeaderBrowserTesting\n",
    "#siewert_values = get_values(\"https://raw.githubusercontent.com/hen95/HTTPHeaderBrowserTesting/main/transform_to_testcase.py\", r\"\\'Strict-Transport-Security: (.*?)\\'\")\n",
    "siewert_values = ['max-age=60; max-age=120', 'max-age=60; someDirective, max-age=60; someDirective', 'max-age=60; preload', 'max-age=0, max-age=60', 'max-age=60, max-age=60; max-age=60; includeSubdomains', 'max-age=60; includeSubDomains', 'random, includeSubdomains; max-age=60; includeSubdomains', 'max-age=60; max-age=0', 'max-age=60, max-age=120', 'max-age=60, max-age=60', 'max-age=60; max-age=60, includeSubdomains', 'max-age=60, includeSubdomains; max-age=60; includeSubdomains', 'includeSubDomains', 'max-age=60; max-age=60', 'max-age=60,; includeSubdomains', 'max-age=60; preload; preload', 'max-age=60', 'max-age=0', 'max-age=60; includeSubDomains; preload', 'max-age=60, x; max-age=60; includeSubdomains', 'max-age=60; includeSubdomains; max-age=60, includeSubdomains', 'max-age=60; includeSubDomains, max-age=60; includeSubDomains', 'max-age=60, includeSubdomains', 'max-age=60; someDirective; someDirective', 'max-age=60, max-age=0', 'max-age=0; max-age=60', 'max-age=120', 'max-age=60; includeSubDomains; includeSubDomains', 'preload', 'max-age=60; preload, max-age=60; preload', 'x, max-age=60; max-age=60; includeSubdomains', 'max-age=60; includeSubdomains, max-age=60', 'max-age=60; ,']\n",
    "# https://crawler.ninja/files/sts-values.txt\n",
    "#crawler_ninja_values = get_crawler_values(\"https://crawler.ninja/files/sts-values.txt\")\n",
    "crawler_ninja_values = get_crawler_values(\"cached_crawler-ninja_values/sts-values.txt\")\n",
    "own_values = [\"includeSubDomains\", \"max-age=-5\", \"max-age=60; includeSubDomains; preload\"]\n",
    "other_values = basic_values + wpt_values + siewert_values + crawler_ninja_values + own_values\n",
    "other_values = expand_urls(other_values)\n",
    "ht = HeaderTests(label, header_name, alt_names, block_values, allow_values, partial_values, legacy_values, other_values)\n",
    "ht.create_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5de1d05a-608b-4db2-b8f1-c1a70210a639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3909\n",
      "Created: 3880\n",
      "[([('permissions-policy', 'fullscreen=()')], 'PP', 200, 'parsing'), ([('x-permissions-policy', 'fullscreen=()')], 'PP', 200, 'parsing'), ([('feature-policy', 'fullscreen=()')], 'PP', 200, 'parsing'), ([('mpermissions-policy', 'fullscreen=()')], 'PP', 200, 'parsing'), ([('permissions„policy', 'fullscreen=()')], 'PP', 200, 'parsing')]\n"
     ]
    }
   ],
   "source": [
    "label = \"PP\"\n",
    "header_name = \"permissions-policy\"\n",
    "alt_names = [\"x-permissions-policy\", \"feature-policy\"]\n",
    "block_values = [\"fullscreen=()\"]\n",
    "allow_values = [\"fullscreen=(*)\"]\n",
    "partial_values = [\"fullscreen=(self)\"]\n",
    "legacy_values = []\n",
    "# Always start with the empty value and then an INVALID value (e.g., \"INVALID\"), after that both valid and invalid values can be added\n",
    "# We use the first two in `mult_headers_test`\n",
    "basic_values = [\"\", \"INVALID\", \"null\", \"*\", URL_REP]\n",
    "# https://wpt.fyi/results/permissions-policy/reporting?label=master&label=experimental&aligned&q=fullscreen\n",
    "wpt_values = [] # Nothing useful?\n",
    "# https://github.com/hen95/HTTPHeaderBrowserTesting\n",
    "siewert_values = [] # Not tested\n",
    "# https://crawler.ninja/files/fp-values.txt, https://crawler.ninja/files/pp-values.txt\n",
    "#crawler_ninja_values = get_crawler_values(\"https://crawler.ninja/files/fp-values.txt\", min_count=4) + get_crawler_values(\"https://crawler.ninja/files/pp-values.txt\", min_count=4)\n",
    "crawler_ninja_values = get_crawler_values(\"cached_crawler-ninja_values/fp-values.txt\", min_count=4) + get_crawler_values(\"cached_crawler-ninja_values/pp-values.txt\", min_count=4)\n",
    "own_values = [\"fullscreen=\", \"fullscreen=*\", \"fullscreen=()\", \"fullscreen=(self)\", f\"fullscreen=({URL_REP})\", \"fullscreen=(self none)\", \"fullscreen=(self,none)\", \"fullscreen=(src)\"]\n",
    "other_values = basic_values + wpt_values + siewert_values + crawler_ninja_values + own_values\n",
    "other_values = expand_urls(other_values)\n",
    "ht = HeaderTests(label, header_name, alt_names, block_values, allow_values, partial_values, legacy_values, other_values)\n",
    "ht.create_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "afe0ec51-e088-49f8-b05a-f6809dbd268f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2837\n",
      "Created: 2797\n",
      "[([('referrer-policy', 'no-referrer')], 'RP', 200, 'parsing'), ([('x-referrer-policy', 'no-referrer')], 'RP', 200, 'parsing'), ([('referer-policy', 'no-referrer')], 'RP', 200, 'parsing'), ([('\\x16referrer-policy', 'no-referrer')], 'RP', 200, 'parsing'), ([('(referrer-policy', 'no-referrer')], 'RP', 200, 'parsing')]\n"
     ]
    }
   ],
   "source": [
    "label = \"RP\"\n",
    "header_name = \"referrer-policy\"\n",
    "alt_names = [\"x-referrer-policy\", \"referer-policy\"]\n",
    "block_values = [\"no-referrer\"]\n",
    "allow_values = [\"unsafe-url\"]\n",
    "partial_values = [\"same-origin\"]\n",
    "legacy_values = []\n",
    "# Always start with the empty value and then an INVALID value (e.g., \"INVALID\"), after that both valid and invalid values can be added\n",
    "# We use the first two in `mult_headers_test`\n",
    "basic_values = [\"\", \"INVALID\", \"null\", \"*\", URL_REP]\n",
    "# https://wpt.fyi/results/referrer-policy?label=master&label=experimental&aligned&q=referrer-policy\n",
    "wpt_values = [] # Too many?\n",
    "# https://github.com/hen95/HTTPHeaderBrowserTesting\n",
    "siewert_values = [] # Not tested\n",
    "# https://crawler.ninja/files/rp-values.txt\n",
    "#crawler_ninja_values = get_crawler_values(\"https://crawler.ninja/files/rp-values.txt\")\n",
    "crawler_ninja_values = get_crawler_values(\"cached_crawler-ninja_values/rp-values.txt\")\n",
    "\n",
    "own_values = [\"no-referrer-when-downgrade\", \"origin\", \"strict-origin\", \"origin-when-cross-origin\", \"strict-origin-when-cross-origin\"]\n",
    "other_values = basic_values + wpt_values + siewert_values + crawler_ninja_values + own_values\n",
    "other_values = expand_urls(other_values)\n",
    "ht = HeaderTests(label, header_name, alt_names, block_values, allow_values, partial_values, legacy_values, other_values)\n",
    "ht.create_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e04fef47-c3d2-4d3a-a9cb-dee6b297976f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1610\n",
      "Created: 1601\n",
      "[([('timing-allow-origin', 'null')], 'TAO', 200, 'parsing'), ([('x-timing-allow-origin', 'null')], 'TAO', 200, 'parsing'), ([('timing-alclow-origin', 'null')], 'TAO', 200, 'parsing'), ([('timing-allow-originw', 'null')], 'TAO', 200, 'parsing'), ([('@timing-allow-origin', 'null')], 'TAO', 200, 'parsing')]\n"
     ]
    }
   ],
   "source": [
    "label = \"TAO\"\n",
    "header_name = \"timing-allow-origin\"\n",
    "alt_names = [\"x-timing-allow-origin\"]\n",
    "block_values = [\"null\"]\n",
    "allow_values = [\"*\"]\n",
    "partial_values = []\n",
    "legacy_values = []\n",
    "# Always start with the empty value and then an INVALID value (e.g., \"INVALID\"), after that both valid and invalid values can be added\n",
    "# We use the first two in `mult_headers_test`\n",
    "basic_values = [\"\", \"INVALID\", \"null\", \"*\", URL_REP]\n",
    "# https://wpt.fyi/results/resource-timing?label=master&label=experimental&aligned&q=tao\n",
    "wpt_values = [] # Nothing crazy?\n",
    "# https://github.com/hen95/HTTPHeaderBrowserTesting\n",
    "siewert_values = [] # Not tested\n",
    "crawler_ninja_values = [] # Not tested\n",
    "own_values = [\"self\", \"'self'\", f\"{URL_REP} {URL_REP}\", f\"{URL_REP},{URL_REP}\"]\n",
    "other_values = basic_values + wpt_values + siewert_values + crawler_ninja_values + own_values\n",
    "other_values = expand_urls(other_values)\n",
    "ht = HeaderTests(label, header_name, alt_names, block_values, allow_values, partial_values, legacy_values, other_values)\n",
    "ht.create_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "90301348-a1b0-462a-a7da-ae582146b598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915\n",
      "Created: 889\n",
      "[([('x-content-type-options', 'nosniff')], 'XCTO', 200, 'parsing'), ([('content-type-options', 'nosniff')], 'XCTO', 200, 'parsing'), ([('x-content-type-options[', 'nosniff')], 'XCTO', 200, 'parsing'), ([('x’content’type’options', 'nosniff')], 'XCTO', 200, 'parsing'), ([('}x-content-type-options', 'nosniff')], 'XCTO', 200, 'parsing')]\n"
     ]
    }
   ],
   "source": [
    "label = \"XCTO\"\n",
    "header_name = \"x-content-type-options\"\n",
    "alt_names = [\"content-type-options\"]\n",
    "block_values = [\"nosniff\"]\n",
    "allow_values = []\n",
    "partial_values = []\n",
    "legacy_values = []\n",
    "# Always start with the empty value and then an INVALID value (e.g., \"INVALID\"), after that both valid and invalid values can be added\n",
    "# We use the first two in `mult_headers_test`\n",
    "basic_values = [\"\", \"INVALID\", \"nosniff\", \"no-sniff\"]\n",
    "# https://github.com/web-platform-tests/wpt/blob/master/fetch/nosniff/resources/x-content-type-options.json\n",
    "wpt_values = [\"NOSNIFF\", \"nosniff,,@#$#%%&^&^*()()11!\", \"@#$#%%&^&^*()()11!,nosniff\", \"no\", \"\", \",nosniff\", \"nosniff\\u000C\", \"nosniff\\u000B,nosniff\", \"'NosniFF'\", '\"nosniFF\"'] \n",
    "# https://github.com/hen95/HTTPHeaderBrowserTesting\n",
    "siewert_values = [] # Not tested\n",
    "#crawler_ninja_values = get_crawler_values(\"https://crawler.ninja/files/xcto-values.txt\")\n",
    "crawler_ninja_values = get_crawler_values(\"cached_crawler-ninja_values/xcto-values.txt\")\n",
    "\n",
    "own_values = [\"SNIFF\", \"no\", \"always\", \"maybe\"]\n",
    "other_values = basic_values + wpt_values + siewert_values + crawler_ninja_values + own_values\n",
    "other_values = expand_urls(other_values)\n",
    "ht = HeaderTests(label, header_name, alt_names, block_values, allow_values, partial_values, legacy_values, other_values)\n",
    "ht.create_all_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8f957b3-fb07-49ce-880e-b2138a815b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458\n",
      "Created: 1440\n",
      "[([('COnTENT-sECURITY-PolICy', \"frame-ancestors 'none'\"), ('X-fRAME-oPTIONS', 'DENY')], 'CSPvsXFO', 200, 'parsing'), ([('COnTENT-sECURITY-PolICy', 'frame-ancestors *'), ('X-fRAME-oPTIONS', '')], 'CSPvsXFO', 200, 'parsing'), ([('COnTENT-sECURITY-PolICy', \"frame-ancestors 'self'\"), ('X-fRAME-oPTIONS', 'INVALID')], 'CSPvsXFO', 200, 'parsing'), ([('COnTENT-sECURITY-PolICy', ''), ('X-fRAME-oPTIONS', 'SAMEORIGIN')], 'CSPvsXFO', 200, 'parsing'), ([('COnTENT-sECURITY-PolICy', 'INVALID'), ('X-fRAME-oPTIONS', 'DENY')], 'CSPvsXFO', 200, 'parsing')]\n"
     ]
    }
   ],
   "source": [
    "label = \"CSPvsXFO\"\n",
    "header_names = [\"content-security-policy\", \"x-frame-options\"]\n",
    "values = {\n",
    "    \"content-security-policy\": csp_fa_all,\n",
    "    \"x-frame-options\": [\"DENY\", \"\", \"INVALID\", \"SAMEORIGIN\"]\n",
    "}\n",
    "ht = HeaderTestsMultHeader(header_names, values, label)\n",
    "ht.create_all_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
